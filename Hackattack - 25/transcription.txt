We will look into two different approaches of saving a train model to a file which you can use later on to load the model from a file into a memory and use that to make actual predictions. Solving a problem using machine learning consists of two steps typically. The first step is training a model using your training dataset and the second step is to ask your questions to the train model which short of looks like a human brain and that will give you the answers. Often the size of the training dataset is pretty huge because as the size increases your model becomes more accurate. It is like if you are doing a football training and if you train yourself more and more, you become more and more batter at your football game. And when your training dataset is so huge often it is in like gigabytes, The training step becomes more time consuming if you save the train model to a file you can later on use that same model to make the actual prediction so you don't need to train it every time you want to ask these questions, right? So if you have it saved to a file now I don't have a training step here and I can directly ask a question so that's what we are going to look into today I will write a Python code to save that model to a file. Here I have a Jupyter Notebook which I used in my first tutorial of linear regression of predicting home prizes. The code here is pretty straightforward. I am loading home prizes from my CSV file and then using linear regression to make that your prediction. And here is saying that 5,000 square feet home is going to cost me 800 So let's use Python's pickle module. Now you guys might be aware about pickle module already. It allows you to serialize your Python object into a file. So here I will use the file. So I'll first save with open model pickle. And I'm going to to write binary data. Hence, I'm using WB mode in the file. So first, I'm opening a file. And then what I will do is I will say pickle dot dump dump my model into this file. When I run this, what actually happens is in my working directory, it created this model pickle file, which if I open in my not pad looks like this. This is some gibberish and it is expected to be gibberish because it's a binary file. Okay, you actually don't need to care about the content here But what you need to know is your model is saved into a file now Now you can use the same model here. So what I can do is here I can say model is equal to Pickle dump load the file. Okay, so again, I have to open the file pointer. So it's the same file. But this time I'm using it in a read mode. And it's a binary file. Hence, I have supplied B here. Now I have my model loaded from a file into a memory and MP is the object. If I use now MP object to make the prediction, I want to ask what is the price of my 5000 square feet home, then you can see that it will give me the same answer as I got it here at this step. So this is beautiful because now I can supply this model file to a friend of mine and I can say, okay, here is my train model or a train brain. Go use it for your actual problem. All right. So you can ask the questions to this model and it will give the answers. There is a second approach of saving model to a file which is using SQL on joblib. So if you Google So as you learn model persistent, you will find this link where ascalons document documentation shows how you can use joblib to do essentially the same thing. So then if it is doing the same thing, then what's the difference between pickle and joblib? As per the documentation, if your model consists of large numpy arrays, then using joblib might be more efficient. Now I have not done any profiling but you can go ahead and do it on your own and figure out which one you want to use. But usually people say that when you have a lot of numpy arrays, joblib tends to be more efficient. But essentially it gives you the same functionality. So I will first import joblib. In Jupyter Notebook, you can hit tab and it will show you the autocomplete. So here there is external modules from that I will import joblib. Now the difference between joblib API and pickle API is that joblib can take the file them directly. So I have my model and I want to save that model to a file. I will say model joblib. When execute this, it's save this model to this particular file. And when I go to my working directory, I will find this file here. It is just updated right now. 631 is the timestamp. When I open that file into not paired, I will again see some gibberish because this is also a binary file. Again, you don't care about the content here. What you need to know is your model is successfully saved. And you can load that model using joblib.load, give the file name. In return, you get your model object back. And that model object, you can use to make actual prediction. And it gives you the same answer here. What it is saving inside that binary file, is different things such as, for example, if you look at coefficient, the coefficient is same as what I got it here. So it's saving all these essential pieces for your model. Okay, that's all I had for this tutorial. I don't have any exercise today, but you can go ahead and save your model using joblib and pickle into a file. I have gone through linear regression models today but you can pretty much save any other kind of machine learning models using these two awesome models.